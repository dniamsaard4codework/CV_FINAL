‡πÇ‡∏≠‡πÄ‡∏Ñ ‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ú‡∏°‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‚Äú‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‚Äù ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏¢ ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÉ‡∏ô‡∏™‡πÑ‡∏•‡∏î‡πå‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏ô‡∏∞
(‡πÄ‡∏ô‡πâ‡∏ô‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏ö‡πà‡∏≠‡∏¢ + ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢)

---

## 1) Optimization, Neural Network, CNN & Image Classification

### Q1: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ pipeline ‡∏Å‡∏≤‡∏£ train ‡πÇ‡∏°‡πÄ‡∏î‡∏• deep learning ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö image classification

**A:**

1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° dataset ‚Üí ‡πÅ‡∏ö‡πà‡∏á train / val / test
2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î model (‡πÄ‡∏ä‡πà‡∏ô linear classifier / MLP / CNN)
3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î loss function (‡πÄ‡∏ä‡πà‡∏ô cross-entropy)
4. ‡∏™‡∏∏‡πà‡∏° initialize weights
5. ‡∏ó‡∏≥ forward pass ‚Üí ‡πÑ‡∏î‡πâ prediction
6. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì loss
7. ‡∏ó‡∏≥ backward pass (backpropagation) ‚Üí ‡πÑ‡∏î‡πâ gradient ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ weight
8. ‡πÉ‡∏ä‡πâ optimizer (‡πÄ‡∏ä‡πà‡∏ô SGD / Adam) ‡∏õ‡∏£‡∏±‡∏ö weights ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î loss
9. ‡∏ß‡∏ô step 5‚Äì8 ‡∏´‡∏•‡∏≤‡∏¢ epoch ‡πÅ‡∏•‡∏∞ monitor val set ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ overfitting

---

### Q2: Gradient Descent ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**A:**

* ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ optimization ‡∏ó‡∏µ‡πà ‚Äú‡πÄ‡∏î‡∏¥‡∏ô‡∏•‡∏á‡πÄ‡∏Ç‡∏≤‚Äù ‡∏ï‡∏≤‡∏°‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà loss ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
* ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡∏≤‡∏°‡∏™‡∏π‡∏ï‡∏£:
  [
  w := w - \eta \nabla_w J(w)
  ]
  ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà (\eta) = learning rate, (\nabla_w J(w)) = gradient ‡∏Ç‡∏≠‡∏á loss w.r.t. w

---

### Q3: ‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Gradient Descent, SGD, Mini-batch SGD

**A:**

* **Full-batch GD**: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô dataset ‚Üí ‡πÅ‡∏°‡πà‡∏ô‡πÅ‡∏ï‡πà‡∏ä‡πâ‡∏≤
* **SGD**: ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠ step ‚Üí ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å‡πÅ‡∏ï‡πà noisy ‡∏°‡∏≤‡∏Å
* **Mini-batch SGD**: ‡πÉ‡∏ä‡πâ batch ‡∏Ç‡∏ô‡∏≤‡∏î B (‡πÄ‡∏ä‡πà‡∏ô 32, 64) ‚Üí trade-off ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß, ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

---

### Q4: ‡∏ñ‡πâ‡∏≤ learning rate ‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ / ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏∂‡πâ‡∏ô?

**A:**

* ‡πÄ‡∏•‡πá‡∏Å‡πÑ‡∏õ ‚Üí loss ‡∏•‡∏î‡∏ä‡πâ‡∏≤, train ‡∏ô‡∏≤‡∏ô, ‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡∏¥‡∏î local minima
* ‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏õ ‚Üí ‡∏Ç‡πâ‡∏≤‡∏° minima, loss ‡πÅ‡∏Å‡∏ß‡πà‡∏á‡∏´‡∏£‡∏∑‡∏≠ diverge
  ‚Üí ‡∏à‡∏∂‡∏á‡∏°‡∏µ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ **learning rate decay** (step, cosine, linear, inverse sqrt ‡∏Ø‡∏•‡∏Ø) ‡πÅ‡∏•‡∏∞ **adaptive LR** ‡πÄ‡∏ä‡πà‡∏ô Adam, Adagrad ‡∏Ø‡∏•‡∏Ø

---

### Q5: Backpropagation ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£? ‡πÉ‡∏ä‡πâ chain rule ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**A:**

* ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏´‡∏≤ (\frac{\partial J}{\partial w_i}) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å weight
* ‡πÉ‡∏ä‡πâ **chain rule** ‡∏¢‡πâ‡∏≠‡∏ô‡∏à‡∏≤‡∏Å output layer ‚Üí hidden layers ‚Üí input
* ‡∏ï‡∏≤‡∏°‡∏Å‡∏£‡∏≤‡∏ü computation: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß propagate ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ node

---

### Q6: Activation function ‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ activation ‡πÄ‡∏•‡∏¢‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£?

**A:**

* ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà: ‡πÉ‡∏™‡πà non-linearity ‡∏ó‡∏≥‡πÉ‡∏´‡πâ network ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ approximate ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
* ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏î‡∏µ: differentiable, ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏á‡πà‡∏≤‡∏¢, ‡∏°‡∏±‡∏Å monotonic
* ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ activation (‡∏ó‡∏∏‡∏Å layer ‡πÄ‡∏õ‡πá‡∏ô linear) ‚Üí ‡∏ó‡∏±‡πâ‡∏á network = linear transformation ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‚Üí ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö linear classifier ‡∏¢‡∏±‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÅ‡∏°‡πâ‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ layer ‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£

---

### Q7: ‡∏ó‡∏≥‡πÑ‡∏° CNN ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ fully-connected (MLP) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û?

**A:**

* FC layer ‡∏°‡∏≠‡∏á input ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå 1D ‚Üí ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û
* ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ó‡∏∏‡∏Å pixel ‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å neuron)
* CNN ‡πÉ‡∏ä‡πâ **convolution filter** ‡∏ó‡∏µ‡πà:

  * shared weights ‚Üí ‡πÉ‡∏ä‡πâ filter ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏™‡πÅ‡∏Å‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û
  * local receptive field ‚Üí ‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô feature ‡πÉ‡∏´‡∏ç‡πà
    ‚Üí ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤, ‡πÉ‡∏ä‡πâ pattern ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏û, ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô vision

---

### Q8: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î output ‡∏Ç‡∏≠‡∏á convolution layer

‡πÉ‡∏´‡πâ Input size = (W), filter size = (K), padding = (P), stride = (S)
**A:**
[
W_\text{out} = \frac{W - K + 2P}{S} + 1
]

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: Input 32x32, filter 5x5, P=2, S=1 ‚Üí
[
(32 - 5 + 2\times2)/1 + 1 = 32
]
‡∏ñ‡πâ‡∏≤‡∏°‡∏µ 10 filters ‚Üí output volume = 10 √ó 32 √ó 32 

---

### Q9: Receptive field ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏•‡∏á stack conv ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô?

**A:**

* Receptive field = ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡πÉ‡∏ô input ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Ñ‡πà‡∏≤ pixel ‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô feature map
* ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ conv kernel size = K, ‡πÑ‡∏°‡πà‡∏°‡∏µ stride
* ‡∏î‡πâ‡∏ß‡∏¢ L layers ‚Üí receptive field size = (1 + L (K - 1))
  ‡πÄ‡∏ä‡πà‡∏ô L=2, K=3 ‚Üí RF = 5x5 

---

## 2) Object Detection (R-CNN, Fast/Faster R-CNN, IoU, mAP, NMS, YOLO/SSD) 

### Q10: Object detection ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å image classification ‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á?

**A:**

* Classification: ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û ‚Üí ‡∏ó‡∏≤‡∏¢ ‚Äú‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‚Äù (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á)
* Detection:

  * ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≤‡∏¢ ‚Äú‡∏´‡∏•‡∏≤‡∏¢ object‚Äù ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
  * ‡πÅ‡∏ï‡πà‡∏•‡∏∞ object ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏ó‡∏±‡πâ‡∏á **class label** ‡πÅ‡∏•‡∏∞ **bounding box (x,y,w,h)**
  * ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ object ‡∏Ñ‡∏ô‡∏•‡∏∞‡∏Ç‡∏ô‡∏≤‡∏î/‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á/‡∏à‡∏≥‡∏ô‡∏ß‡∏ô ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô

---

### Q11: ‡∏ô‡∏¥‡∏¢‡∏≤‡∏° IoU (Intersection over Union) ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?

**A:**

* ‡πÉ‡∏´‡πâ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ = (B_p), ‡∏Å‡∏•‡πà‡∏≠‡∏á ground truth = (B_{gt})
  [
  IoU = \frac{\text{‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô (intersection)}}{\text{‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏•‡∏£‡∏ß‡∏° (union)}}
  ]
* ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠:

  * ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏ß‡πà‡∏≤ detection ‚Äú‡∏ï‡∏£‡∏á‚Äù ‡∏Å‡∏±‡∏ö GT ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÄ‡∏ä‡πà‡∏ô IoU > 0.5 ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ñ‡∏π‡∏Å)
  * ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô NMS ‡πÅ‡∏•‡∏∞ metric ‡∏≠‡∏¢‡πà‡∏≤‡∏á mAP 

---

### Q12: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á R-CNN (training + test-time)

**A:**
**Train:**

1. ‡πÉ‡∏ä‡πâ region proposal (‡πÄ‡∏ä‡πà‡∏ô Selective Search) ‡∏™‡∏£‡πâ‡∏≤‡∏á ~2000 proposals / image
2. Crop region ‚Üí resize ‡πÄ‡∏õ‡πá‡∏ô 224√ó224 ‚Üí ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ CNN (pretrained ImageNet)
3. Extract feature (‡πÄ‡∏ä‡πà‡∏ô fc7) ‡πÅ‡∏•‡πâ‡∏ß train SVM ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™ (C+1 classes: ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™ + background)
4. Train regressor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö bounding box (box regression)

**Test:**

1. ‡∏£‡∏±‡∏ô region proposal ‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏°‡πà
2. crop & resize ‡πÅ‡∏ï‡πà‡∏•‡∏∞ region ‚Üí ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ CNN ‚Üí ‡πÑ‡∏î‡πâ feature
3. SVM ‚Üí class scores, regressor ‚Üí box refine
4. ‡πÉ‡∏ä‡πâ NMS ‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢: ‡∏ï‡πâ‡∏≠‡∏á forward CNN ~2000 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á / ‡∏£‡∏π‡∏õ ‚Üí ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å 

---

### Q13: Fast R-CNN ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏≠‡∏á R-CNN? ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**A:**
‡∏õ‡∏±‡∏ç‡∏´‡∏≤: R-CNN ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô CNN ‡∏ï‡πà‡∏≠ region ‚Üí ‡∏ä‡πâ‡∏≤

‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£ Fast R-CNN:

1. ‡∏£‡∏±‡∏ô CNN ‡∏Å‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û ‚Äú‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‚Äù ‚Üí ‡πÑ‡∏î‡πâ feature map
2. Project region proposals ‡∏•‡∏á‡∏ö‡∏ô feature map
3. ‡πÉ‡∏ä‡πâ **ROI Pool** (‡∏´‡∏£‡∏∑‡∏≠ ROI Align) crop ‡πÅ‡∏û‡∏ï‡∏ä‡πå feature ‡πÅ‡∏ï‡πà‡∏•‡∏∞ region ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏á‡∏ó‡∏µ‡πà ‡πÄ‡∏ä‡πà‡∏ô 7√ó7
4. ‡∏™‡πà‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ ROI ‡πÄ‡∏Ç‡πâ‡∏≤ fully-connected layers ‚Üí ‡∏ó‡∏≤‡∏¢ class + box refinement

‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏£‡∏≤‡∏∞ share convolution features ‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û 

---

### Q14: ROI Pool vs ROI Align ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:**

* **ROI Pool**

  * quantize ‡∏û‡∏¥‡∏Å‡∏±‡∏î bounding box ‡πÄ‡∏õ‡πá‡∏ô grid integer
  * ‡∏ó‡∏≥ max-pooling ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ bin ‚Üí ‡πÄ‡∏Å‡∏¥‡∏î **quantization error** (‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á feature shift ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢)
* **ROI Align**

  * ‡πÑ‡∏°‡πà quantize ‡πÄ‡∏õ‡πá‡∏ô integer
  * ‡πÉ‡∏ä‡πâ bilinear interpolation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡∏à‡∏∏‡∏î float ‡πÉ‡∏ô feature map
  * ‡∏•‡∏î misalignment, ‡πÉ‡∏´‡πâ localization ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô

---

### Q15: Faster R-CNN ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏∞‡πÑ‡∏£‡∏à‡∏≤‡∏Å Fast R-CNN? Region Proposal Network (RPN) ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**A:**

* Fast R-CNN ‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ ‚ÄúSelective Search‚Äù ‡∏ö‡∏ô CPU ‚Üí ‡∏ä‡πâ‡∏≤
* Faster R-CNN ‡πÄ‡∏û‡∏¥‡πà‡∏° **RPN** ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô CNN ‡πÄ‡∏•‡πá‡∏Å‡∏ö‡∏ô feature map ‡πÄ‡∏î‡∏¥‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠ **predict region proposals** ‡πÄ‡∏≠‡∏á
* ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á feature map ‡πÄ‡∏£‡∏≤‡∏ß‡∏≤‡∏á **anchor boxes** ‡∏´‡∏•‡∏≤‡∏¢‡∏™‡πÄ‡∏Å‡∏•/‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô ‡πÅ‡∏•‡πâ‡∏ß RPN ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢

  * objectness score (‡πÄ‡∏õ‡πá‡∏ô object ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà)
  * box regression ‡∏Ç‡∏≠‡∏á anchor ‡∏ô‡∏±‡πâ‡∏ô
* ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏≠‡∏≤ proposals ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ ROI Pool / ROI Align ‡∏ï‡πà‡∏≠‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Fast R-CNN

---

### Q16: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á Non-Maximum Suppression (NMS)

**A:**
‡πÉ‡∏´‡πâ detections ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏´‡∏ô‡∏∂‡πà‡∏á:

1. ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ï‡∏≤‡∏° score ‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å ‚Üí ‡∏ô‡πâ‡∏≠‡∏¢
2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà score ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‚Üí ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
3. ‡∏•‡∏ö‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ IoU ‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ > threshold (‡πÄ‡∏ä‡πà‡∏ô 0.7)
4. ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 2‚Äì3 ‡∏à‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠

NMS ‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ã‡πâ‡∏≥‡∏Ç‡∏≠‡∏á object ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô 

---

### Q17: mAP (mean Average Precision) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö object detection ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**A:**
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™:

1. ‡∏£‡∏±‡∏ô detector ‡∏ö‡∏ô‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û (‡∏û‡∏£‡πâ‡∏≠‡∏° NMS)
2. ‡πÄ‡∏£‡∏µ‡∏¢‡∏á detection ‡∏ï‡∏≤‡∏° score ‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å ‚Üí ‡∏ô‡πâ‡∏≠‡∏¢
3. ‡πÅ‡∏ï‡πà‡∏•‡∏∞ detection:

   * ‡∏ñ‡πâ‡∏≤ match ‡∏Å‡∏±‡∏ö GT (IoU > 0.5) ‡πÅ‡∏•‡∏∞ GT ‡∏ô‡∏±‡πâ‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ ‚Üí ‡∏ô‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô True Positive
   * ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà ‚Üí False Positive
4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Precision, Recall ‡∏ó‡∏µ‡∏•‡∏∞‡∏à‡∏∏‡∏î ‚Üí ‡πÑ‡∏î‡πâ PR curve
5. **Average Precision (AP)** = ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ï‡πâ PR curve
6. **mAP** = ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á AP ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™

* COCO mAP: ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ AP ‡∏ó‡∏µ‡πà IoU ‡∏´‡∏•‡∏≤‡∏¢ threshold (0.5, 0.55, ‚Ä¶, 0.95) 

---

## 3) Object Tracking & Change Detection

### Q18: ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‚ÄúObject Tracking‚Äù ‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?

**A:**

* ‡πÉ‡∏´‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏†‡∏≤‡∏û (video) ‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á (x,y) ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ t
* ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: estimate ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏•‡∏∞ **state** ‡∏Ç‡∏≠‡∏á object ‡πÉ‡∏ô region ‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤
* state ‡∏≠‡∏≤‡∏à‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢: ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß, ‡∏Ç‡∏ô‡∏≤‡∏î bounding box, appearance descriptor ‡∏Ø‡∏•‡∏Ø
* ‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô

  * Single-target tracking
  * Detection + tracking (0 ‡∏´‡∏£‡∏∑‡∏≠ 1 object)
  * Multi-target detection and tracking (‡∏´‡∏•‡∏≤‡∏¢ object)

---

### Q19: ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ tracking ‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏°‡∏µ detector ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß?

**A:**

* Detector ‡∏≠‡∏≤‡∏à‡∏û‡∏•‡∏≤‡∏î object ‡πÉ‡∏ô‡∏ö‡∏≤‡∏á frame ‡πÄ‡∏û‡∏£‡∏≤‡∏∞

  * occlusion
  * blur / ‡πÅ‡∏™‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô / viewpoint ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
  * background clutter
* Tracking‡∏ä‡πà‡∏ß‡∏¢

  * fill-in ‡∏Å‡∏≤‡∏£ detect ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ä‡πà‡∏ß‡∏á‡∏™‡∏±‡πâ‡∏ô‡πÜ
  * ‡πÉ‡∏ä‡πâ motion model ‡∏ó‡∏≤‡∏¢ trajectory ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏î‡∏¥‡∏ô‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡∏ô‡∏ô‡πÑ‡∏´‡∏°) 

---

### Q20: ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á tracking ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?

**A:**

1. **Detection** ‚Äì ‡∏´‡∏≤ candidate objects ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ frame
2. **Data Association** ‚Äì ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà detection ‡πÉ‡∏ô frame ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Å‡∏±‡∏ö track ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà (‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÑ‡∏´‡∏°)
3. **Prediction** ‚Äì ‡πÉ‡∏ä‡πâ motion model ‡∏ó‡∏≤‡∏¢‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢ association ‡πÅ‡∏•‡∏∞ handle missing detections 

---

### Q21: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Simple Background Subtraction ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î

**A:**

* ‡∏°‡∏µ background model ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û ‚Äú‡∏â‡∏≤‡∏Å‡∏ô‡∏¥‡πà‡∏á‚Äù (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏)
* ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ frame:

  * ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì |I_t(x,y) ‚Äì B(x,y)|
  * threshold ‚Üí foreground (‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô) vs background (‡∏ô‡∏¥‡πà‡∏á)
    **‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î**
* ‡∏ñ‡πâ‡∏≤‡∏™‡∏¥‡πà‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏¢‡∏∏‡∏î ‚Üí ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å detect ‡∏ï‡∏•‡∏≠‡∏î‡πÑ‡∏õ (ghost, outdated background)
* ‡∏ñ‡πâ‡∏≤ background ‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ç‡∏¢‡∏±‡∏ö ‚Üí ‡∏ó‡∏±‡πâ‡∏á object ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ú‡∏¢ background ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å detect
* ‡πÅ‡∏û‡πâ illumination change, shadow, tree swaying ‡∏Ø‡∏•‡∏Ø
* global threshold ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û 

---

### Q22: Frame differencing ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å background subtraction ‡∏¢‡∏±‡∏á‡πÑ‡∏á? ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢?

**A:**

* ‡πÉ‡∏ä‡πâ frame t ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö frame t-1 ‡πÄ‡∏õ‡πá‡∏ô background ‡πÅ‡∏ó‡∏ô‡∏†‡∏≤‡∏û‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ñ‡∏á‡∏ó‡∏µ‡πà
  **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**
* ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡πá‡∏ß‡∏ï‡πà‡∏≠‡πÅ‡∏™‡∏á/‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏±‡πà‡∏ô
* ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏∏‡∏î‡∏ô‡∏¥‡πà‡∏á‡∏à‡∏∞‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏à‡∏≤‡∏Å foreground (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô ghost)
  **‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**
* ‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏à‡∏≠‡πÅ‡∏Ñ‡πà ‚Äú‡∏Ç‡∏≠‡∏ö‡∏ô‡∏≥/‡∏ó‡πâ‡∏≤‡∏¢‚Äù ‡∏Ç‡∏≠‡∏á object ‚Üí ‡πÑ‡∏î‡πâ pixel foreground ‡∏ô‡πâ‡∏≠‡∏¢
* ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á/‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏¢‡∏≤‡∏Å 

---

### Q23: Adaptive Background Subtraction (exponential moving average) ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£? trade-off ‡∏Ç‡∏≠‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå Œ± ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**A:**

* update background ‡∏ï‡∏≤‡∏°‡∏™‡∏π‡∏ï‡∏£ (‡∏ï‡πà‡∏≠ pixel):
  [
  B_t = (1-\alpha)B_{t-1} + \alpha I_t
  ]
* (\alpha = 0) ‚Üí background fixed (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô simple subtraction)
* (\alpha = 1) ‚Üí ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö frame differencing
  **Trade-off:**
* Œ± ‡∏™‡∏π‡∏á: ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡πá‡∏ß‡∏ï‡πà‡∏≠‡πÅ‡∏™‡∏á/‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏±‡πà‡∏ô, ‡πÅ‡∏ï‡πà object ‡πÉ‡∏´‡∏ç‡πà-‡∏ä‡πâ‡∏≤ ‡∏à‡∏∞‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡∏•‡∏∞‡∏•‡∏≤‡∏¢‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô background
* Œ± ‡∏ï‡πà‡∏≥: object/ghost ‡∏´‡∏≤‡∏¢‡∏ä‡πâ‡∏≤ ‡πÅ‡∏ï‡πà background ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô 

---

### Q24: ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Gaussian Mixture Model (GMM) ‡πÉ‡∏ô background modeling?

**A:**

* intensity ‡∏Ç‡∏≠‡∏á pixel ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ô‡∏≤‡∏ô‡πÜ ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô **‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏´‡∏°‡∏î** ‡πÄ‡∏ä‡πà‡∏ô

  * ‡∏ñ‡∏ô‡∏ô (‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡πÜ)
  * ‡∏´‡∏¥‡∏°‡∏∞‡∏ï‡∏Å (noise)
  * ‡∏£‡∏ñ‡∏ú‡πà‡∏≤‡∏ô‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á
* ‡πÉ‡∏´‡πâ pixel ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏°‡∏µ distribution ‡πÄ‡∏õ‡πá‡∏ô **mixture ‡∏Ç‡∏≠‡∏á K Gaussian** ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏°‡∏µ weight, mean, variance
* Gaussians ‡∏ó‡∏µ‡πà‡∏°‡∏µ weight ‡∏™‡∏π‡∏á‡πÅ‡∏•‡∏∞ variance ‡∏ï‡πà‡∏≥ (‡∏≠‡∏¢‡∏π‡πà‡∏ö‡πà‡∏≠‡∏¢ / ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏ô‡∏¥‡πà‡∏á) ‚Üí ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô background
* Gaussians ‡∏ó‡∏µ‡πà weight ‡πÄ‡∏•‡πá‡∏Å ‚Üí foreground

‡∏ä‡πà‡∏ß‡∏¢ handle background ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô tree swaying, noise, shadow 

---

### Q25: Tracking-by-detection ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ß‡∏¥‡∏ò‡∏µ feature-based ‡πÄ‡∏ä‡πà‡∏ô SIFT tracking

**A:**

* **Tracking-by-detection**: ‡∏ó‡∏∏‡∏Å frame ‡πÄ‡∏£‡∏≤ detect/‡∏´‡∏≤ feature ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà (match) ‡πÄ‡∏û‡∏∑‡πà‡∏≠ track object
* ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á SIFT-based tracking:

  1. Frame 1: user ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å bounding box ‡πÄ‡∏õ‡πá‡∏ô object
  2. ‡∏™‡∏Å‡∏±‡∏î SIFT features ‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á (object set O) ‡πÅ‡∏•‡∏∞ background (set B)
  3. Frame t: ‡∏™‡∏Å‡∏±‡∏î SIFT ‡πÉ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û
  4. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ feature: ‡∏´‡∏≤ distance ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡∏±‡∏ö O ‡πÅ‡∏•‡∏∞‡∏Å‡∏±‡∏ö B ‚Üí ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì score ‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô object ‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô
  5. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å search window: ‡∏£‡∏ß‡∏° score ‡∏Ç‡∏≠‡∏á feature ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô + penalty ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á/‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏°‡∏≤‡∏Å‡πÑ‡∏õ
  6. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å window ‡∏ó‡∏µ‡πà score ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á object ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡πâ‡∏ß update object model ‡∏ï‡πà‡∏≠‡πÑ‡∏õ 

---

### Q26: GOTURN (learning-based tracker) ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**A:**

* ‡πÉ‡∏ä‡πâ CNN regression network ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö

  * crop ‡∏Ç‡∏≠‡∏á object ‡∏à‡∏≤‡∏Å frame t-1
  * crop search area ‡∏à‡∏≤‡∏Å frame t
    ‚Üí ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ bounding box ‡∏Ç‡∏≠‡∏á object ‡πÉ‡∏ô frame t 
    **‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**
* ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á train online ‡∏ï‡πà‡∏≠ object ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß ‚Üí ‡πÄ‡∏£‡πá‡∏ß (100 FPS)
* ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ template matching ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô feature ‡πÄ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ deep network
  **‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
* ‡∏™‡∏°‡∏°‡∏ï‡∏¥ motion ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á smooth ‚Üí ‡∏ñ‡πâ‡∏≤ object ‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡πÄ‡∏£‡πá‡∏ß‡∏≠‡∏≠‡∏Å‡∏ô‡∏≠‡∏Å search window ‚Üí track ‡∏´‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏¢‡∏≤‡∏Å

---

## 4) Image Segmentation (Classical + Deep)

### Q27: Image segmentation ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å classification / detection ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**A:**

* **Classification**: ‡∏ó‡∏≤‡∏¢ label ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û
* **Detection**: ‡∏ó‡∏≤‡∏¢ bounding boxes + label ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ object
* **Segmentation**: ‡∏ó‡∏≤‡∏¢ label **‡∏ó‡∏∏‡∏Å pixel** ‡πÉ‡∏ô‡∏†‡∏≤‡∏û

  * **Semantic segmentation**: pixels ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô object ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÅ‡∏ä‡∏£‡πå label ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡πÅ‡∏¢‡∏Å instance)
  * **Instance segmentation**: ‡πÅ‡∏¢‡∏Å instance ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏Ñ‡∏ô 3 ‡∏Ñ‡∏ô = 3 instance)
  * **Panoptic**: ‡∏£‡∏ß‡∏° semantic + instance

---

### Q28: ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î ‚Äúsegmentation as clustering‚Äù ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? pixel feature vector ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á?

**A:**

* ‡∏°‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô **feature space** ‡πÄ‡∏ä‡πà‡∏ô
  [
  f = [R, G, B, x, y, d, \dots]
  ]
* Pixel ‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡∏£‡∏∞‡∏¢‡∏∞ Euclidean ‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô) ‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà cluster ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
* ‡πÉ‡∏ä‡πâ clustering algorithm ‡πÄ‡∏ä‡πà‡∏ô k-means / mean shift ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° pixels ‡πÄ‡∏õ‡πá‡∏ô segments 

---

### Q29: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô k-means clustering ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö segmentation ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏î‡∏µ/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:** 

1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô cluster = k
2. Initialize centroid (m_1, ‚Ä¶, m_k) ‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô
3. Assign: ‡πÉ‡∏´‡πâ pixel ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà cluster ‡∏ó‡∏µ‡πà centroid ‡πÉ‡∏Å‡∏•‡πâ‡∏™‡∏∏‡∏î
4. Update: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì mean ‡πÉ‡∏´‡∏°‡πà‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ cluster (‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ feature ‡∏Ç‡∏≠‡∏á pixels ‡πÉ‡∏ô cluster ‡∏ô‡∏±‡πâ‡∏ô)
5. ‡∏ó‡∏≥ step 3‚Äì4 ‡∏ã‡πâ‡∏≥‡∏à‡∏ô centroid ‡∏Ç‡∏¢‡∏±‡∏ö‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤ threshold

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**

* ‡∏á‡πà‡∏≤‡∏¢, ‡πÄ‡∏£‡πá‡∏ß, implement ‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏Å
  **‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢:**
* ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î k ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤
* sensitive ‡∏ï‡πà‡∏≠ initialization
* sensitive ‡∏ï‡πà‡∏≠ outlier
* ‡πÑ‡∏°‡πà enforce spatial smoothness ‚Üí pixel ‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏≠‡∏¢‡∏π‡πà‡∏™‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡∏≠‡∏¢‡∏π‡πà cluster ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

---

### Q30: Mean Shift segmentation ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏ô density ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£? ‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å k-means ‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:** 

* ‡∏°‡∏≠‡∏á distribution ‡∏Ç‡∏≠‡∏á points ‡πÉ‡∏ô feature space ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤ ‚Äúmode‚Äù (‡∏à‡∏∏‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á density)
* ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö mean shift:

  1. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡∏´‡∏ô‡∏∂‡πà‡∏á (initial mean)
  2. ‡∏ß‡∏≤‡∏á window (kernel) ‡∏£‡∏≠‡∏ö‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ
  3. ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡πÉ‡∏ô window ‚Üí ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô mean ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏´‡∏≤‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á density
  4. ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏à‡∏ô mean ‡πÅ‡∏ó‡∏ö‡πÑ‡∏°‡πà‡∏Ç‡∏¢‡∏±‡∏ö ‚Üí ‡πÑ‡∏î‡πâ mode
* Points ‡∏ó‡∏µ‡πà converge ‡πÑ‡∏õ mode ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‚Üí ‡∏≠‡∏¢‡∏π‡πà cluster ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

**‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å k-means:**

* ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î k ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô cluster ‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏≠‡∏á‡∏à‡∏≤‡∏Å density)
* handle ‡∏£‡∏π‡∏õ‡∏ó‡∏£‡∏á cluster ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏á‡∏Å‡∏•‡∏°/convex)
* ‡πÅ‡∏ï‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ä‡πâ‡∏≤, ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡∏ô‡∏≤‡∏î window ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

---

### Q31: Graph-based segmentation ‡∏î‡πâ‡∏ß‡∏¢ Min-Cut / Normalized Cut ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**A:** 

* ‡∏™‡∏£‡πâ‡∏≤‡∏á **‡∏Å‡∏£‡∏≤‡∏ü**:

  * ‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel = vertex
  * ‡∏°‡∏µ edge ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° pixel ‡πÉ‡∏Å‡∏•‡πâ‡πÜ ‡∏Å‡∏±‡∏ô (‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏π‡πà)
  * ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å edge = affinity (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á pixel ‡∏™‡∏≠‡∏á‡∏ï‡∏±‡∏ß)
* Min-cut: ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô (A,B) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏ú‡∏•‡∏£‡∏ß‡∏° weight ‡∏Ç‡∏≠‡∏á edges ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î

  * ‡πÅ‡∏ï‡πà‡∏à‡∏∞ bias ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏•‡πá‡∏Å‡πÜ (‡πÄ‡∏û‡∏£‡∏≤‡∏∞ cost ‡∏ô‡πâ‡∏≠‡∏¢)
* Normalized Cut (NCut): ‡πÄ‡∏û‡∏¥‡πà‡∏° term normalization ‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á ‚Äú‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏≠‡∏á subgraph‚Äù

  * ‡∏•‡∏î bias ‡∏ï‡πà‡∏≠ partition ‡πÄ‡∏•‡πá‡∏Å
  * ‡πÅ‡∏ï‡πà‡πÅ‡∏Å‡πâ‡πÅ‡∏ö‡∏ö exact ‡πÄ‡∏õ‡πá‡∏ô NP-complete ‚Üí ‡πÉ‡∏ä‡πâ eigenvector-based approximation

---

### Q32: Semantic Segmentation ‡∏î‡πâ‡∏ß‡∏¢ Fully Convolutional Network (FCN) ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å sliding window ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**A:** 

* **Sliding window**:

  * ‡∏ï‡∏±‡∏î patch ‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡∏£‡∏≠‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel ‚Üí ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ classifier
  * ‡πÑ‡∏°‡πà reuse feature ‡∏Ç‡∏≠‡∏á patch ‡∏ó‡∏µ‡πà overlap ‡∏Å‡∏±‡∏ô ‚Üí ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å
* **FCN**:

  * ‡πÉ‡∏ä‡πâ conv layers ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÑ‡∏°‡πà‡∏°‡∏µ FC ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö)
  * ‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏û ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á feature map ‚Üí upsample ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ resolution ‡∏™‡∏π‡∏á ‡πÅ‡∏•‡πâ‡∏ß output per-pixel score map
  * share computation ‡∏ö‡∏ô feature map ‚Üí ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏Å‡∏ß‡πà‡∏≤

---

### Q33: ‡∏ß‡∏¥‡∏ò‡∏µ upsampling ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô semantic segmentation ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á? ‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:** 

* **Unpooling**

  * ‡πÉ‡∏ä‡πâ ‚Äúswitch‚Äù ‡∏à‡∏≤‡∏Å max-pooling ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢ max
* **Interpolation**

  * Nearest neighbor / bilinear / bicubic ‚Üí ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå, purely geometric
* **Transposed Convolution (Deconv)**

  * convolution transpose ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ kernel ‡πÑ‡∏î‡πâ
  * ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ learnable upsampling ‚Üí ‡∏Ç‡∏¢‡∏≤‡∏¢ resolution ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û

---

### Q34: Transposed Convolution ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ (‡πÄ‡∏ä‡∏¥‡∏á intuition)?

**A:**

* ‡∏õ‡∏Å‡∏ï‡∏¥ convolution: ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î (downsample) ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ stride > 1
* Transposed convolution: ‡∏ó‡∏≥‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ ‚Äú‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‚Äù

  * input size ‡πÄ‡∏•‡πá‡∏Å ‚Üí output size ‡πÉ‡∏´‡∏ç‡πà
  * kernel ‡∏ñ‡∏π‡∏Å spread ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡πÉ‡∏ô output space ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≤‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ñ‡∏π‡∏Å sum
* ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô layer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö learnable upsampling ‡πÉ‡∏ô decoder ‡∏Ç‡∏≠‡∏á segmentation / generator ‡πÉ‡∏ô GAN ‡∏Ø‡∏•‡∏Ø 

---

## 5) 3D Vision & 3D Deep Learning

### Q35: 2.5D (Depth Map) ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å full 3D representation ‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:**

* Depth map: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel ‡πÉ‡∏ô‡∏†‡∏≤‡∏û ‡∏ö‡∏≠‡∏Å ‚Äú‡∏£‡∏∞‡∏¢‡∏∞‚Äù ‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ñ‡∏∂‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß

  * ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏≤‡∏Å‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (visible surface) ‚Üí ‡πÄ‡∏•‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏Å 2.5D
* Full 3D: ‡πÅ‡∏™‡∏î‡∏á shape ‡∏ó‡∏±‡πâ‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏ô space (‡∏£‡∏ß‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏°‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô) ‡πÄ‡∏ä‡πà‡∏ô point cloud, mesh, voxel

---

### Q36: ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3D representations ‡∏´‡∏•‡∏±‡∏Å‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏î‡∏µ/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢

**A:** 

* **Point Cloud**

  * ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ: ‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö raw sensor (LiDAR), ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢, flexible, scalable
  * ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢: ‡πÑ‡∏°‡πà‡∏°‡∏µ connectivity ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô, render ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô‡∏¢‡∏≤‡∏Å
* **Polygon Mesh** (vertices + faces)

  * ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ: ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏¥‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô, render ‡∏™‡∏ß‡∏¢, ‡∏°‡∏µ‡∏Å‡∏≤‡∏£ up/down-sampling ‡πÑ‡∏î‡πâ
  * ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢: ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô, ‡πÅ‡∏Å‡πâ topology ‡∏¢‡∏≤‡∏Å
* **Voxel Grid**

  * ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ: ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô grid ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ 3D CNN, ‡πÅ‡∏ó‡∏ô shape ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
  * ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢: memory ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠ resolution ‡∏™‡∏π‡∏á
* **Implicit (SDF, level set)**

  * ‡πÅ‡∏™‡∏î‡∏á shape ‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô f(p)=0 (surface), f(p) < 0 / >0 = inside / outside
  * ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ: inside‚Äìoutside test ‡∏á‡πà‡∏≤‡∏¢, topological change ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏™‡∏ß‡∏¢
  * ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢: sampling / rendering ‡∏¢‡∏∏‡πà‡∏á‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤

---

### Q37: Point cloud ‚Äúorganized‚Äù vs ‚Äúunorganized‚Äù ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**A:** 

* **Organized**: points ‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (rows, columns) ‡πÄ‡∏ä‡πà‡∏ô depth image ‡∏à‡∏≤‡∏Å RGB-D camera

  * ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏∏‡∏î‡πÑ‡∏´‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏û ‚Üí ‡πÄ‡∏£‡πá‡∏ß‡∏ï‡πà‡∏≠‡∏ö‡∏≤‡∏á algorithm
* **Unorganized**: points ‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ñ‡∏•‡∏∞‡πÜ ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô grid (‡πÄ‡∏ä‡πà‡∏ô LiDAR scan)

  * ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏° (kd-tree ‡∏Ø‡∏•‡∏Ø) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á

---

### Q38: Point Cloud ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ-‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?

**A:** 
**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ:**

* ‡πÉ‡∏Å‡∏•‡πâ raw sensor, ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏á‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å 3D scanner ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å
* ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÅ‡∏Ñ‡πà‡∏à‡∏∏‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å)
  **‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î:**
* ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤/‡∏´‡∏•‡∏±‡∏á (connectivity)
* smoothing / rendering ‡∏™‡∏ß‡∏¢‡πÜ ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥ mesh reconstruction
* tasks ‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡πÄ‡∏ä‡πà‡∏ô inside‚Äìoutside test) ‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ implicit

---

### Q39: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ difference ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á explicit vs implicit 3D representation

**A:** 

* **Explicit**: ‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß/‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÄ‡∏ä‡πà‡∏ô point cloud, mesh, voxel occupancy

  * sampling ‡∏á‡πà‡∏≤‡∏¢ (‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß)
  * ‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏° ‚Äú‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤‚Äù (inside/outside) ‡∏≠‡∏≤‡∏à‡∏¢‡∏≤‡∏Å
* **Implicit**: ‡πÅ‡∏ó‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô f(x,y,z)

  * surface = {p | f(p)=0} (‡πÄ‡∏ä‡πà‡∏ô sphere: (x^2 + y^2 + z^2 - r^2 = 0))
  * inside/outside test ‡∏á‡πà‡∏≤‡∏¢: sign ‡∏Ç‡∏≠‡∏á f
  * ‡πÅ‡∏ï‡πà sampling surface ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ mesh ‡∏™‡∏ß‡∏¢‡πÜ ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ algorithm ‡πÄ‡∏û‡∏¥‡πà‡∏° (marching cubes ‡∏Ø‡∏•‡∏Ø)

---

### Q40: Signed Distance Function (SDF) ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**A:** 

* ‡πÄ‡∏õ‡πá‡∏ô implicit function f(p) ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ = ‡∏£‡∏∞‡∏¢‡∏∞ signed ‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î p ‡∏ñ‡∏∂‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß

  * f(p) = 0 ‡∏ö‡∏ô surface
  * f(p) < 0 ‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô
  * f(p) > 0 ‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å
* ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏ó‡∏±‡πâ‡∏á inside/outside ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏¢‡∏∞‡∏ñ‡∏∂‡∏á‡∏ú‡∏¥‡∏ß‡πÉ‡∏ô‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‚Üí ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô reconstruction / rendering / 3D deep learning

---

### Q41: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ pipeline ‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ ‡∏Ç‡∏≠‡∏á point cloud registration

**A:** 

1. Detect keypoints ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÄ‡∏ä‡πà‡∏ô ‡∏°‡∏∏‡∏°, ‡∏Ç‡∏≠‡∏ö) ‚Äì ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥: repeatable, distinctive
2. Estimate feature descriptor ‡∏£‡∏≠‡∏ö keypoint (‡πÄ‡∏ä‡πà‡∏ô PFH, VFH)
3. Matching descriptors ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏á point clouds ‚Üí ‡πÑ‡∏î‡πâ candidate correspondences
4. ‡πÉ‡∏ä‡πâ RANSAC ‡πÄ‡∏û‡∏∑‡πà‡∏≠ reject outliers ‡πÅ‡∏•‡∏∞ estimate transformation ‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ
5. Refinement ‡∏î‡πâ‡∏ß‡∏¢ ICP ‡∏Ø‡∏•‡∏Ø ‡πÉ‡∏´‡πâ alignment ‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô
6. ‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠ fusion, mapping, pose estimation ‡∏Ø‡∏•‡∏Ø

---

### Q42: PointNet ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏ô 3D deep learning?

**A:** 

* ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: point cloud ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà **unordered** (‡∏™‡∏•‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏à‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß shape ‡πÄ‡∏î‡∏¥‡∏°)
* PointNet ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö network ‡∏ó‡∏µ‡πà

  * ‡πÉ‡∏ä‡πâ MLP ‡∏Å‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î (shared weights)
  * ‡πÉ‡∏ä‡πâ symmetric function (‡πÄ‡∏ä‡πà‡∏ô max pooling) aggregate ‡πÄ‡∏õ‡πá‡∏ô global feature ‚Üí invariant ‡∏ï‡πà‡∏≠ permutation
* ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ feature ‡∏à‡∏≤‡∏Å point cloud ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö classification, segmentation, part labeling ‡∏Ø‡∏•‡∏Ø

---

## 6) Generative Models (AE, VAE, GAN) ‚Äì ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏¢‡∏≠‡∏î‡∏Æ‡∏¥‡∏ï

*(‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¥‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ä‡∏≤ ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå)*

### Q43: Autoencoder ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?

**A:**

* neural network ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏≠‡∏á‡∏™‡πà‡∏ß‡∏ô: encoder + decoder
* Encoder: map input x ‚Üí latent z
* Decoder: map z ‚Üí reconstruct (\hat{x})
* Train ‡∏î‡πâ‡∏ß‡∏¢ objective ‡πÉ‡∏´‡πâ reconstruction error ‡∏ï‡πà‡∏≥ (‡πÄ‡∏ä‡πà‡∏ô MSE ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á x ‡∏Å‡∏±‡∏ö (\hat{x}))
* ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: dimensionality reduction, denoising, feature learning ‡∏Ø‡∏•‡∏Ø

---

### Q44: VAE ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å AE ‡∏ï‡∏£‡∏á‡πÑ‡∏´‡∏ô? ‡∏ó‡∏≥‡πÑ‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ ‚Äúvariational‚Äù?

**A:**

* ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞ map x ‚Üí z ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡πÜ, VAE ‡πÉ‡∏´‡πâ encoder ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á distribution (q_\phi(z|x)) (‡πÄ‡∏ä‡πà‡∏ô Gaussian: mean, log-variance)
* ‡πÉ‡∏ä‡πâ reparameterization trick: (z = \mu + \sigma \odot \epsilon, \epsilon \sim \mathcal{N}(0, I))
* loss = reconstruction loss + KL divergence ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á (q_\phi(z|x)) ‡∏Å‡∏±‡∏ö prior (p(z)) (‡πÄ‡∏ä‡πà‡∏ô N(0, I))
* ‡∏ó‡∏≥‡πÉ‡∏´‡πâ latent space ‚Äúsmooth‚Äù ‡πÅ‡∏•‡∏∞ generative ‡πÑ‡∏î‡πâ (sample z ‡∏à‡∏≤‡∏Å prior ‚Üí decode ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà)

---

### Q45: GAN ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á? Train ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**A:**

* Two networks:

  * Generator G(z) ‚Äì ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏õ‡∏•‡∏≠‡∏°‡∏à‡∏≤‡∏Å noise z
  * Discriminator D(x) ‚Äì ‡πÅ‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ‡∏à‡∏£‡∏¥‡∏á (‡∏à‡∏≤‡∏Å data) ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏•‡∏≠‡∏° (‡∏à‡∏≤‡∏Å G)
* Objective ‡πÅ‡∏ö‡∏ö minimax:

  * D ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° maximize ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏à‡∏£‡∏¥‡∏á/‡∏õ‡∏•‡∏≠‡∏°
  * G ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° generate ‡πÉ‡∏´‡πâ D ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏£‡∏¥‡∏á
* ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: G ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ distribution ‡∏Ç‡∏≠‡∏á data ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô data ‡∏à‡∏£‡∏¥‡∏á

---

‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ú‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô **‡∏Ç‡πâ‡∏≠‡∏™‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì** ‡πÄ‡∏ä‡πà‡∏ô

* ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì output size ‡∏Ç‡∏≠‡∏á conv ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏±‡πâ‡∏ô
* ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì IoU ‡∏Ç‡∏≠‡∏á‡∏™‡∏≠‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á
* ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö k-means segmentation ‡πÉ‡∏ô feature space [R,G,B,x,y]
* ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏à‡∏ó‡∏¢‡πå conceptual ‡∏¢‡∏≤‡∏ß‡πÜ (‡∏ñ‡∏≤‡∏°‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ pipeline ‡∏Ç‡∏≠‡∏á Faster R-CNN ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ï‡πá‡∏°)

‡πÅ‡∏ï‡πà‡∏ä‡∏∏‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° ‚Äú‡πÅ‡∏Å‡∏ô‡∏´‡∏•‡∏±‡∏Å‚Äù ‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡∏ö‡πà‡∏≠‡∏¢‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡πÅ‡∏•‡πâ‡∏ß üëç
‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡∏ú‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô **flashcard ‡∏™‡∏±‡πâ‡∏ô‡πÜ** ‡πÑ‡∏ß‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏≠‡∏ö‡∏Å‡πá‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
